{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3eabc52e-ea54-49dd-92f1-fd8a9e58f568",
   "metadata": {},
   "source": [
    "# CMSC Final Project\n",
    "\n",
    "#### By Thomas Purtscher\n",
    "\n",
    "## Introduction\n",
    "\n",
    "### Goal\n",
    "\n",
    "The goal of my project is to analyze Counter-Strike: Global Offensive (CS:GO) performance on a map-by-map basis to construct the best team from my group of friends (or if you are following this as a tutorial, your friends) for each map in the game. \n",
    "\n",
    "### Background on CS:GO\n",
    "\n",
    "CS:GO is a 5v5 competitive shooter built in the Source engine, famed for its large esports scene and game mechanics mostly unique to the Counter-Strike franchise (ex. no ADS, extreme inaccuracy while running and shooting). It was released in 2012 and quickly became a major player in the esports scene and is currently one of the most popular competitve shooters. Most people play the game in 5v5 ranked mode, which limits the map pool to a select few that have rotated out throughout the years - the most popular of which being Dust 2, Nuke, Cache, Inferno, and Mirage. \n",
    "\n",
    "These maps are especially notable in the context of CS:GO because of the aforementioned staple mechanics of the Counter-Strike franchise. No ADS means weapons are more limited in their effective ranges and combined with no accurate run-and-gun (at least with rifles) means that your positioning at the start of a fight is incredibly important. The lack of a sprint button only furthers this importance on positioning, and the round-to-round in-game economy means that losing can be much more punishing as you actually lose the weapons you fight with. These factors combined (along with the physics engine of Source and the grenade mechanics in-game) means the map knowledge is absolutely crucial to succeeding in CS:GO, and it means that players will gravitate towards some maps because their experience can give them a serious competitive advantage (especially in professional CS:GO).\n",
    "\n",
    "Every map we will be looking at (and that people play on) uses the defusal gamemode, indicated by the \"de_\" in front of the map name. This gamemode has 5 Counter-Terrorists defending bombsites while the 5 Terrorists attempt to either kill the enemy team within the time or plant the bomb. When the Terrorists plant the bomb, the Counter-Terrorists have 45 seconds to retake the site and defuse it while the Terrorists defend the site, effectively reversing the attack/defense roles\n",
    "\n",
    "## Data\n",
    "\n",
    "The data I will be using to perform the analysis is match history data from [csgostats](csgostats.gg) that covers all matches the player participated in from 2020-2022 (and in my case three extra from 2017-2019, for some reason). This data contains pretty much every stat you would concievably want except for the players you were playing with that game (but I was unable to find a site that does, so it can't be helped).\n",
    "\n",
    "I first attempted to download the html through python from the url, but quickly ran into the issue of being blocked by the captcha of the site which was definitely a new and worrying issue, but this can be circumvented by downloading the html to the site manually and then parsing the html from the files you have obtained. It's less efficient but is an easy workaround, unlike attempting to solve the recaptcha with some AI or paying someone to solve it for you.\n",
    "\n",
    "## Obtaining The Data\n",
    "\n",
    "### Processing The HTML\n",
    "\n",
    "Here we import all the required packages, which I will describe as we use them. The first one we use is BeautifulSoup, which allows us to view the html code more succinctly through bs.prettify(). This gives us a good idea of what we are looking at, and helps in finding the correct table when using pd.read_html(). We are using pandas in this project for the highly useful dataframes the packages provides, giving us a powerful and conivient data management tool. pd.read_html() scans the html file and extracts all the tables it finds, returning them as data frames. Here the table we want is the third of the three tables found on the page, which I will name as \"my_games\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d639352d-8b68-46d2-b6f4-519aa4fe5ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Index(['Date', 'Unnamed: 1', 'Map', 'Score', 'Rank', 'Unnamed: 5', 'K', 'D',\n",
      "       'A', '+/-', 'HS%', 'ADR', '1v5', '1v4', '1v3', '1v2', '1v1', '5k', '4k',\n",
      "       '3k', 'Rating', 'Unnamed: 21'],\n",
      "      dtype='object')\n",
      "                Date  Unnamed: 1          Map  Score  Rank  Unnamed: 5   K  \\\n",
      "0          1 day ago         NaN      de_nuke   16:8   NaN         NaN  17   \n",
      "1     Sat 7th May 22         NaN      de_nuke  16:14   NaN         NaN  12   \n",
      "2     Sat 7th May 22         NaN      de_nuke  11:16   NaN         NaN  29   \n",
      "3     Fri 6th May 22         NaN   de_inferno  11:16   NaN         NaN  17   \n",
      "4     Fri 6th May 22         NaN      de_nuke  14:16   NaN         NaN  25   \n",
      "..               ...         ...          ...    ...   ...         ...  ..   \n",
      "674   Sat 2nd May 20         NaN     de_dust2   16:0   NaN         NaN  23   \n",
      "675  Tue 25th Feb 20         NaN  de_overpass  12:16   NaN         NaN  26   \n",
      "676  Wed 27th Nov 19         NaN      de_nuke   16:3   NaN         NaN  19   \n",
      "677  Tue 23rd Jul 19         NaN   de_inferno  16:11   NaN         NaN  29   \n",
      "678  Tue 28th Nov 17         NaN   de_inferno  15:15   NaN         NaN  28   \n",
      "\n",
      "      D  A  +/-  ...  1v5  1v4  1v3  1v2  1v1  5k  4k  3k  Rating  Unnamed: 21  \n",
      "0    18  7   -1  ...    0    0    0    0    3   0   0   2    0.99   View Match  \n",
      "1    21  7   -9  ...    0    0    0    0    1   0   0   0    0.62   View Match  \n",
      "2    19  3   10  ...    0    0    0    1    1   0   0   3    1.48   View Match  \n",
      "3    24  3   -7  ...    0    0    0    0    0   0   0   3    0.85   View Match  \n",
      "4    26  4   -1  ...    0    0    0    0    1   0   1   2    1.06   View Match  \n",
      "..   .. ..  ...  ...  ...  ...  ...  ...  ...  ..  ..  ..     ...          ...  \n",
      "674   8  6   15  ...    0    0    0    0    0   0   2   1    2.30   View Match  \n",
      "675  23  4    3  ...    0    0    0    0    0   0   0   3    1.17   View Match  \n",
      "676  14  5    5  ...    0    0    0    0    0   0   0   1    1.26   View Match  \n",
      "677  23  5    6  ...    0    0    0    0    0   0   0   1    1.23   View Match  \n",
      "678  20  8    8  ...    0    0    0    0    0   0   0   3    1.34   View Match  \n",
      "\n",
      "[679 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup #html parser & viewer\n",
    "import numpy as np #mathematics package\n",
    "import pandas as pd #provides dataframes and related methods\n",
    "import seaborn as sns #provides our visualizations\n",
    "\n",
    "\n",
    "matches = open(\"Evihunger match history.htm\", \"r\", encoding='utf-8') #opens the html file in python\n",
    "bs = BeautifulSoup(matches.read())\n",
    "pretty = bs.prettify()\n",
    "#print(pretty) #used to preview the html\n",
    "readtable = pd.read_html(str(bs)) #read tables from the html\n",
    "print(len(readtable))\n",
    "print(readtable[2].columns)\n",
    "my_games = readtable[2] #fetches the proper table\n",
    "print(my_games)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcc43b2-9c35-4cc9-8516-78f37bb67a20",
   "metadata": {},
   "source": [
    "#### Results\n",
    "\n",
    "Our read table looks pretty good but there are some things we need to clean up. Firstly there are several NaN columns that need to be removed. These columns are mostly either nonsense columns (I am assuming used for formatting) or the \"Rank\" column which holds the image of the rank you were at when you played the game. \n",
    "\n",
    "### Processing The Dataframe Of Matches\n",
    "\n",
    "Our first step is to process the \"Score\" column into three boolean columns \"W\", \"T\", and \"L\", representing Win, Tie, and Loss respectively. There is something to be said for counting the number of rounds and averaging kills per round, but I elected not to do that. We already have ADR as a round-dependent stat which will prevent short games from throwing off our statistics. Counting rounds could also serve for \"how much of a win/loss\" the win/loss was, but this really is up to you; me and my friends tend to throw a few rounds when we're winning so even if we genuinely dominate the other team the score might not reflect it. Because of that I am not going to count rounds, as it would likely be unreliable and thus not very useful. I will also be deleting the \"Date\" column because all of these games are *relatively* recent and for most of this time period (last 3 years) me and my friends have been about the same in rank and skill. Finally, I will be deleting the \"Rank\" column not just because it is NA but because CSGO has one of the most unreliable and innacurate ranking systems in a modern competitve game - low ranks will sometimes be matched with high ranks and the variance in skill within each rank is extremely high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a902b5cd-86f1-4a2e-b765-c7a048c20192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Map   K   D  A  +/-  HS%  ADR  1v5  1v4  1v3  1v2  1v1  5k  4k  \\\n",
      "0        de_nuke  17  18  7   -1   59   96    0    0    0    0    3   0   0   \n",
      "1        de_nuke  12  21  7   -9   75   57    0    0    0    0    1   0   0   \n",
      "2        de_nuke  29  19  3   10   41  103    0    0    0    1    1   0   0   \n",
      "3     de_inferno  17  24  3   -7   35   79    0    0    0    0    0   0   0   \n",
      "4        de_nuke  25  26  4   -1   40   95    0    0    0    0    1   0   1   \n",
      "..           ...  ..  .. ..  ...  ...  ...  ...  ...  ...  ...  ...  ..  ..   \n",
      "674     de_dust2  23   8  6   15   35  150    0    0    0    0    0   0   2   \n",
      "675  de_overpass  26  23  4    3   38   97    0    0    0    0    0   0   0   \n",
      "676      de_nuke  19  14  5    5   42  103    0    0    0    0    0   0   0   \n",
      "677   de_inferno  29  23  5    6   66  105    0    0    0    0    0   0   0   \n",
      "678   de_inferno  28  20  8    8   61  111    0    0    0    0    0   0   0   \n",
      "\n",
      "     3k  Rating      W      T      L  \n",
      "0     2    0.99   True  False  False  \n",
      "1     0    0.62   True  False  False  \n",
      "2     3    1.48  False  False   True  \n",
      "3     3    0.85  False  False   True  \n",
      "4     2    1.06  False  False   True  \n",
      "..   ..     ...    ...    ...    ...  \n",
      "674   1    2.30   True  False  False  \n",
      "675   3    1.17  False  False   True  \n",
      "676   1    1.26   True  False  False  \n",
      "677   1    1.23   True  False  False  \n",
      "678   3    1.34  False   True  False  \n",
      "\n",
      "[679 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "#changing score to string\n",
    "my_games['Score'] = my_games['Score'].astype(\"string\")\n",
    "#creating win/tie/loss columns\n",
    "my_games['W'] = False\n",
    "my_games['T'] = False\n",
    "my_games['L'] = False\n",
    "\n",
    "#marks wins/losses\n",
    "index = 0\n",
    "while index < len(my_games.Map):\n",
    "    scores = my_games.at[index, 'Score'].split(\":\")\n",
    "    if int(scores[0]) > int(scores[1]):\n",
    "        my_games.loc[index, 'W'] = True\n",
    "    elif int(scores[0]) == int(scores[1]):\n",
    "        my_games.loc[index, 'T'] = True\n",
    "    else:\n",
    "        my_games.loc[index, 'L'] = True\n",
    "    index += 1\n",
    "\n",
    "#removing unnecessary columns\n",
    "my_games = my_games.drop(['Date', 'Unnamed: 1', 'Rank', 'Unnamed: 5', 'Unnamed: 21', \"Score\"], axis = 1)\n",
    "print(my_games)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3ff0b2-4cf4-46fe-969d-b9c671573da0",
   "metadata": {},
   "source": [
    "#### Results\n",
    "\n",
    "Now our dataframe is far nicer to look at, and can easily be further processed by our program.\n",
    "\n",
    "### Maps\n",
    "\n",
    "Now we need to identify what maps have been played in the dataset to determine what maps are needed to make summary statistics for - the list of which can be generated by using .unique() on the \"Map\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "543e06a5-75d9-48da-b381-0c75dd9aafba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['de_nuke' 'de_inferno' 'de_vertigo' 'de_cache' 'de_mirage' 'de_iris'\n",
      " 'de_basalt' 'de_ancient' 'cs_insertion2' 'de_overpass' 'de_dust2'\n",
      " 'cs_office' 'de_train' 'cs_agency']\n"
     ]
    }
   ],
   "source": [
    "maps = my_games.Map.unique() #get all the maps\n",
    "print(maps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8a19a3-993c-46a1-80a8-5596e3f3ff22",
   "metadata": {},
   "source": [
    "#### Results\n",
    "\n",
    "We now have the list of maps in the dataset.\n",
    "\n",
    "### Creating Per Map Summary Statistics\n",
    "\n",
    "Because we have the list of maps, now we can make the statistics summarized across all games for each map. I made a list of every map and then turned that into the first column of a new dataframe and made empty columns for each summary statistic. Means are calculated with np.mean() and standard deviations are calculated with np.std() (np being numpy, a powerful mathematics package). Most of these columns are pretty self-explanatory aside from the \"plus_minus\" columns: the amount of kills in a game minus the amount of deaths, the \"ADR\" columns: the average damage per round, and the \"Rating\" column: the HLTV.org \"rating\" statistic (calculated based on a variety of variable and designed to measure performance with 1 being average)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19baf982-e25e-4b89-9ac6-75c0a91c2c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Map</th>\n",
       "      <th>mean_K</th>\n",
       "      <th>std_K</th>\n",
       "      <th>mean_D</th>\n",
       "      <th>std_D</th>\n",
       "      <th>mean_A</th>\n",
       "      <th>std_A</th>\n",
       "      <th>mean_HS</th>\n",
       "      <th>std_HS</th>\n",
       "      <th>mean_plus_minus</th>\n",
       "      <th>sum_plus_minus</th>\n",
       "      <th>mean_ADR</th>\n",
       "      <th>std_ADR</th>\n",
       "      <th>mean_Rating</th>\n",
       "      <th>std_Rating</th>\n",
       "      <th>sum_W</th>\n",
       "      <th>sum_T</th>\n",
       "      <th>sum_L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>de_nuke</td>\n",
       "      <td>22.385246</td>\n",
       "      <td>7.412639</td>\n",
       "      <td>17.680328</td>\n",
       "      <td>5.387599</td>\n",
       "      <td>4.122951</td>\n",
       "      <td>2.125481</td>\n",
       "      <td>41.226776</td>\n",
       "      <td>13.186574</td>\n",
       "      <td>4.704918</td>\n",
       "      <td>1722</td>\n",
       "      <td>97.704918</td>\n",
       "      <td>20.510968</td>\n",
       "      <td>1.277623</td>\n",
       "      <td>0.397608</td>\n",
       "      <td>228</td>\n",
       "      <td>34</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>de_inferno</td>\n",
       "      <td>25.093333</td>\n",
       "      <td>6.806219</td>\n",
       "      <td>19.280000</td>\n",
       "      <td>4.136214</td>\n",
       "      <td>4.653333</td>\n",
       "      <td>2.413812</td>\n",
       "      <td>43.253333</td>\n",
       "      <td>11.754254</td>\n",
       "      <td>5.813333</td>\n",
       "      <td>436</td>\n",
       "      <td>102.306667</td>\n",
       "      <td>20.305647</td>\n",
       "      <td>1.330133</td>\n",
       "      <td>0.377693</td>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>de_vertigo</td>\n",
       "      <td>20.759259</td>\n",
       "      <td>7.717069</td>\n",
       "      <td>18.814815</td>\n",
       "      <td>4.290705</td>\n",
       "      <td>4.703704</td>\n",
       "      <td>2.521240</td>\n",
       "      <td>44.611111</td>\n",
       "      <td>12.474295</td>\n",
       "      <td>1.944444</td>\n",
       "      <td>105</td>\n",
       "      <td>96.518519</td>\n",
       "      <td>24.727209</td>\n",
       "      <td>1.167222</td>\n",
       "      <td>0.414820</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>de_cache</td>\n",
       "      <td>22.764706</td>\n",
       "      <td>7.654521</td>\n",
       "      <td>18.264706</td>\n",
       "      <td>4.590968</td>\n",
       "      <td>4.617647</td>\n",
       "      <td>2.376536</td>\n",
       "      <td>40.529412</td>\n",
       "      <td>13.473799</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>153</td>\n",
       "      <td>99.441176</td>\n",
       "      <td>21.364059</td>\n",
       "      <td>1.272353</td>\n",
       "      <td>0.407900</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>de_mirage</td>\n",
       "      <td>23.112245</td>\n",
       "      <td>7.483155</td>\n",
       "      <td>19.193878</td>\n",
       "      <td>4.650342</td>\n",
       "      <td>4.479592</td>\n",
       "      <td>2.454607</td>\n",
       "      <td>41.581633</td>\n",
       "      <td>13.473272</td>\n",
       "      <td>3.918367</td>\n",
       "      <td>384</td>\n",
       "      <td>95.387755</td>\n",
       "      <td>23.217091</td>\n",
       "      <td>1.231020</td>\n",
       "      <td>0.401170</td>\n",
       "      <td>46</td>\n",
       "      <td>18</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Map     mean_K     std_K     mean_D     std_D    mean_A     std_A  \\\n",
       "0     de_nuke  22.385246  7.412639  17.680328  5.387599  4.122951  2.125481   \n",
       "1  de_inferno  25.093333  6.806219  19.280000  4.136214  4.653333  2.413812   \n",
       "2  de_vertigo  20.759259  7.717069  18.814815  4.290705  4.703704  2.521240   \n",
       "3    de_cache  22.764706  7.654521  18.264706  4.590968  4.617647  2.376536   \n",
       "4   de_mirage  23.112245  7.483155  19.193878  4.650342  4.479592  2.454607   \n",
       "\n",
       "     mean_HS     std_HS  mean_plus_minus  sum_plus_minus    mean_ADR  \\\n",
       "0  41.226776  13.186574         4.704918            1722   97.704918   \n",
       "1  43.253333  11.754254         5.813333             436  102.306667   \n",
       "2  44.611111  12.474295         1.944444             105   96.518519   \n",
       "3  40.529412  13.473799         4.500000             153   99.441176   \n",
       "4  41.581633  13.473272         3.918367             384   95.387755   \n",
       "\n",
       "     std_ADR  mean_Rating  std_Rating  sum_W  sum_T  sum_L  \n",
       "0  20.510968     1.277623    0.397608    228     34    104  \n",
       "1  20.305647     1.330133    0.377693     35      7     33  \n",
       "2  24.727209     1.167222    0.414820     25      4     25  \n",
       "3  21.364059     1.272353    0.407900     16      4     14  \n",
       "4  23.217091     1.231020    0.401170     46     18     34  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating data structure to hold per map stats\n",
    "my_per_map_stats = pd.DataFrame(['de_nuke', 'de_inferno', 'de_vertigo', 'de_cache', 'de_mirage', 'de_iris', 'de_basalt', 'de_ancient',\n",
    "                              'cs_insertion2', 'de_overpass', 'de_dust2', 'cs_office', 'de_train', 'cs_agency'],  columns = ['Map'])\n",
    "\n",
    "#creating columns for all the desired stats\n",
    "my_per_map_stats['mean_K'] = 0\n",
    "my_per_map_stats['std_K'] = 0\n",
    "my_per_map_stats['mean_D'] = 0\n",
    "my_per_map_stats['std_D'] = 0\n",
    "my_per_map_stats['mean_A'] = 0\n",
    "my_per_map_stats['std_A'] = 0\n",
    "my_per_map_stats['mean_HS'] = 0\n",
    "my_per_map_stats['std_HS'] = 0\n",
    "my_per_map_stats['mean_plus_minus'] = 0\n",
    "my_per_map_stats['sum_plus_minus'] = 0\n",
    "my_per_map_stats['mean_ADR'] = 0\n",
    "my_per_map_stats['std_ADR'] = 0\n",
    "my_per_map_stats['mean_Rating'] = 0\n",
    "my_per_map_stats['std_Rating'] = 0\n",
    "my_per_map_stats['sum_W'] = 0\n",
    "my_per_map_stats['sum_T'] = 0\n",
    "my_per_map_stats['sum_L'] = 0\n",
    "\n",
    "#calculating per map stats\n",
    "index = 0\n",
    "while index < len(my_per_map_stats.Map):\n",
    "    map_data = my_games[my_games['Map'] == my_per_map_stats.Map[index]]\n",
    "    \n",
    "    my_per_map_stats.loc[index, 'mean_K'] = np.mean(map_data['K'])\n",
    "    my_per_map_stats.loc[index, 'std_K'] = np.std(map_data['K'])\n",
    "    my_per_map_stats.loc[index, 'mean_D'] = np.mean(map_data['D'])\n",
    "    my_per_map_stats.loc[index, 'std_D'] = np.std(map_data['D'])\n",
    "    my_per_map_stats.loc[index, 'mean_A'] = np.mean(map_data['A'])\n",
    "    my_per_map_stats.loc[index, 'std_A'] = np.std(map_data['A'])\n",
    "    my_per_map_stats.loc[index, 'mean_HS'] = np.mean(map_data['HS%'])\n",
    "    my_per_map_stats.loc[index, 'std_HS'] = np.std(map_data['HS%'])\n",
    "    my_per_map_stats.loc[index, 'mean_plus_minus'] = np.mean(map_data['+/-'])\n",
    "    my_per_map_stats.loc[index, 'sum_plus_minus'] = sum(map_data['+/-'])\n",
    "    my_per_map_stats.loc[index, 'mean_ADR'] = np.mean(map_data['ADR'])\n",
    "    my_per_map_stats.loc[index, 'std_ADR'] = np.std(map_data['ADR'])\n",
    "    my_per_map_stats.loc[index, 'mean_Rating'] = np.mean(map_data['Rating'])\n",
    "    my_per_map_stats.loc[index, 'std_Rating'] = np.std(map_data['Rating'])\n",
    "    my_per_map_stats.loc[index, 'sum_W'] = sum(map_data['W'])\n",
    "    my_per_map_stats.loc[index, 'sum_T'] = sum(map_data['T'])\n",
    "    my_per_map_stats.loc[index, 'sum_L'] = sum(map_data['L'])\n",
    "    \n",
    "    index += 1\n",
    "\n",
    "my_per_map_stats.head() #previewing the stats table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a43f0b-e227-42f2-b5bd-c7550c68d076",
   "metadata": {},
   "source": [
    "#### Results\n",
    "\n",
    "Now we have a dataframe of all of our statistics for each map, which should let us investigate our performance on each map.\n",
    "\n",
    "### Getting Our Friend's Stats\n",
    "\n",
    "Obviously a team with just me on it would be the optimal team, however I unfortunately do not have four clones, so I will be requiring some friends to play with and consequently some stats to analyze, so I need to repeat the previous steps but for each of my friends. Again, we have to download & read the html of their stats page for each person (to save space I am doing it in a loop by concatenating strings to create the names of the various HTML files and inputting those into the open() function). After that, we can just repeat the previous steps for each friend by using a loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef532837-5051-4acf-8057-7323382c7bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting tables and raw html for each friend\n",
    "friends = ['Alec', 'Anthony', 'Arian', 'Daniel', 'Danny', 'Dylan', 'Eric', 'Ethan', 'Flynn', 'Issac', 'Jackton', 'Kristen', 'Matt', 'Nathan', 'Sarah', 'Tom', 'Tommy', 'Zack']\n",
    "friend_tables = []\n",
    "for friend in friends:\n",
    "    matches = open((friend + \" CS GO Stats.htm\"), \"r\", encoding='utf-8')\n",
    "    bs = BeautifulSoup(matches.read())\n",
    "    readtable = pd.read_html(str(bs))\n",
    "    friend_tables.append(readtable[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c614303-d3e1-4533-958a-c5ad8de8b3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "friend_stats = []\n",
    "#this I would consider contrived code, its simply easier to walk through the explanation when I am only doing it for myself at first.\n",
    "#I am not counting this towards the 150 lines.\n",
    "for table in friend_tables:\n",
    "    table['Score'] = table['Score'].astype(\"string\")\n",
    "    #Creating win column\n",
    "    table['W'] = False\n",
    "    table['T'] = False\n",
    "    table['L'] = False\n",
    "\n",
    "    index = 0\n",
    "    while index < len(table.Map):\n",
    "        scores = table.at[index, 'Score'].split(\":\")\n",
    "        if int(scores[0]) > int(scores[1]):\n",
    "            table.loc[index, 'W'] = True\n",
    "        elif int(scores[0]) == int(scores[1]):\n",
    "            table.loc[index, 'T'] = True\n",
    "        else:\n",
    "            table.loc[index, 'L'] = True\n",
    "        index += 1\n",
    "\n",
    "    #creating data structure to hold per map stats\n",
    "    per_map_friend_stats = pd.DataFrame(['de_nuke', 'de_inferno', 'de_vertigo', 'de_cache', 'de_mirage', 'de_iris', 'de_basalt', 'de_ancient', 'cs_insertion2', 'de_overpass', 'de_dust2', 'cs_office', 'de_train', 'cs_agency'],  columns = ['Map'])\n",
    "    per_map_friend_stats['mean_K'] = 0\n",
    "    per_map_friend_stats['std_K'] = 0\n",
    "    per_map_friend_stats['mean_D'] = 0\n",
    "    per_map_friend_stats['std_D'] = 0\n",
    "    per_map_friend_stats['mean_A'] = 0\n",
    "    per_map_friend_stats['std_A'] = 0\n",
    "    per_map_friend_stats['mean_HS'] = 0\n",
    "    per_map_friend_stats['std_HS'] = 0\n",
    "    per_map_friend_stats['mean_plus_minus'] = 0\n",
    "    per_map_friend_stats['sum_plus_minus'] = 0\n",
    "    per_map_friend_stats['mean_ADR'] = 0\n",
    "    per_map_friend_stats['std_ADR'] = 0\n",
    "    per_map_friend_stats['mean_Rating'] = 0\n",
    "    per_map_friend_stats['std_Rating'] = 0\n",
    "    per_map_friend_stats['sum_W'] = 0\n",
    "    per_map_friend_stats['sum_T'] = 0\n",
    "    per_map_friend_stats['sum_L'] = 0\n",
    "\n",
    "    #calculating per map stats\n",
    "    index = 0\n",
    "    while index < len(my_per_map_stats.Map):\n",
    "        map_data = table[table['Map'] == my_per_map_stats.Map[index]]\n",
    "\n",
    "        per_map_friend_stats.loc[index, 'mean_K'] = np.mean(map_data['K'])\n",
    "        per_map_friend_stats.loc[index, 'std_K'] = np.std(map_data['K'])\n",
    "        per_map_friend_stats.loc[index, 'mean_D'] = np.mean(map_data['D'])\n",
    "        per_map_friend_stats.loc[index, 'std_D'] = np.std(map_data['D'])\n",
    "        per_map_friend_stats.loc[index, 'mean_A'] = np.mean(map_data['A'])\n",
    "        per_map_friend_stats.loc[index, 'std_A'] = np.std(map_data['A'])\n",
    "        per_map_friend_stats.loc[index, 'mean_HS'] = np.mean(map_data['HS%'])\n",
    "        per_map_friend_stats.loc[index, 'std_HS'] = np.std(map_data['HS%'])\n",
    "        per_map_friend_stats.loc[index, 'mean_plus_minus'] = np.mean(map_data['+/-'])\n",
    "        per_map_friend_stats.loc[index, 'sum_plus_minus'] = sum(map_data['+/-'])\n",
    "        per_map_friend_stats.loc[index, 'mean_ADR'] = np.mean(map_data['ADR'])\n",
    "        per_map_friend_stats.loc[index, 'std_ADR'] = np.std(map_data['ADR'])\n",
    "        per_map_friend_stats.loc[index, 'mean_Rating'] = np.mean(map_data['Rating'])\n",
    "        per_map_friend_stats.loc[index, 'std_Rating'] = np.std(map_data['Rating'])\n",
    "        per_map_friend_stats.loc[index, 'sum_W'] = sum(map_data['W'])\n",
    "        per_map_friend_stats.loc[index, 'sum_T'] = sum(map_data['T'])\n",
    "        per_map_friend_stats.loc[index, 'sum_L'] = sum(map_data['L'])\n",
    "\n",
    "        index += 1\n",
    "    friend_stats.append(per_map_friend_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff42e5d-a092-4b4a-b2d2-2d169b08d3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing out each column \n",
    "for friend in friends:\n",
    "    print(friend)\n",
    "    print(friend_stats[friends.index(friend)].head(1)) #only printing one line to save space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba1e031-4748-4fcd-9aaa-2ca6a67ab4ef",
   "metadata": {},
   "source": [
    "#### Results\n",
    "\n",
    "Now we have that same table of statistics but for each of our friends, which is a big step as we now have the tools to be able to do some real analysis now.\n",
    "\n",
    "### Joining The Dataframes\n",
    "\n",
    "Although the dataframe per person structure we had before is easily readable and convienient for humans, joining it into one dataframe is much easier on the program's end for plotting functions, so we need to join it into one dataframe with pd.concat() (after adding each person's name to their dataframe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac306e1-2a46-42c2-806f-7f1436f9085a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#joining together friend_stats and my stats (my_per_map_stats) into a single dataframe\n",
    "for friend in friends:\n",
    "    friend_stats[friends.index(friend)]['name'] = friend\n",
    "my_per_map_stats['name'] = \"Thomas\"\n",
    "friend_stats.append(my_per_map_stats)\n",
    "friend_stats_joined = pd.concat(friend_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1802439a-7b87-44e9-940c-59b320001d11",
   "metadata": {},
   "source": [
    "#### Results\n",
    "\n",
    "Now we have our combined dataframe of statistics for everyone, meaning we can almost start performing exploratory visualizations.\n",
    "\n",
    "### Additional Data\n",
    "\n",
    "As a bit of additional data, we will take each person's individual matches and combine it into a single dataframe in a similar way to the stats dataframe. These matches are useful for visualizing distributions, and while they would be inefficient to use for selecting each player, they are very useful in visualizing the distribution of each stat, and can make some beautiful violin plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5171c22c-a9ea-41ae-b059-fff2dc271c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#joining together friend_tables and my_games into a single dataframe\n",
    "for friend in friends:\n",
    "    friend_tables[friends.index(friend)]['name'] = friend\n",
    "my_games['name'] = \"Thomas\"\n",
    "friend_tables.append(my_games)\n",
    "friend_tables_joined = pd.concat(friend_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f543ac7e-e222-4f01-9fc6-8852bfd7480d",
   "metadata": {},
   "source": [
    "#### Results\n",
    "\n",
    "Now we have our combined dataframe of matches for everyone, meaning we can start making exploratory visualizations.\n",
    "\n",
    "## Exploratory Visualizations\n",
    "\n",
    "### Kills Per Map Per Player\n",
    "\n",
    "The first visualizations we are going to make are scatter plots of kills per map per player. The friend name will be the x axis with the map being designated by the color of the point. This seems like an obvious first visualization to make because kills are an easily understandable and simple statistic to identify impact on a game. We will be using seaborn (a package for plotting) due to the ease of use and aesthetics of it's visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15785a6b-9dcc-43b9-af76-012b18f14dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = sns.catplot(x = \"name\", y = \"mean_K\", hue = \"Map\", jitter = False, height = 6, aspect = 3, data = friend_stats_joined)\n",
    "plot.set(xlabel =\"Friend\", ylabel = \"Mean Kills per Game\", title ='Mean Kills per Map per Player')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fddcef-18d7-4bdd-8c1b-98767230b881",
   "metadata": {},
   "source": [
    "#### Results\n",
    "\n",
    "The plot worked, but the data isnt nearly as consistent as we would like. The difference between all the different players isn't that much, and there is a huge amount of variance within each player.\n",
    "\n",
    "### Filtering the Data\n",
    "\n",
    "This does support the idea that per map statistics are valuable, but this level of variance is a little strange, so lets attempt to filter to maps with more than 10 games. This should increase the difference between each player by filtering out statistically insignificant results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40f58e5-5643-4aa7-a99c-4fcc27b7a136",
   "metadata": {},
   "outputs": [],
   "source": [
    "friend_stats_sigificant = friend_stats_joined[friend_stats_joined[\"sum_W\"] + friend_stats_joined[\"sum_T\"] + friend_stats_joined[\"sum_L\"]  > 10]\n",
    "plot = sns.catplot(x = \"name\", y = \"mean_K\", hue = \"Map\", jitter = False, height = 6, aspect = 3, data = friend_stats_sigificant)\n",
    "plot.set(xlabel =\"Friend\", ylabel = \"Mean Kills per Game\", title ='Mean Kills per Map per Player, Maps with > 10 Games')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7874570e-29df-4844-a711-7c19594518e9",
   "metadata": {},
   "source": [
    "#### Results\n",
    "\n",
    "This plot looks a lot better and accurately shows both variation on a per-map basis (some players are better at certain maps) and variation between players (some people are better than others), and it also corroborates my personal experience. I love inferno so it's not surprise that it's my best map, and Danny sucks in general.\n",
    "\n",
    "### Testing ADR Per Map Per Player\n",
    "\n",
    "Before we move into per-map analysis let's quickly try making the same visualization but with ADR instead of kills to see if there is any large disparity. Lower ADR/Kill will tend to occur when people are baiting other teammates, having them fight the enemy and die to they can easily clean up (having the knowledge of the enemy's positioning + the damage inflicted by your teammate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fb9c7b-e507-4810-9e47-2e856704f318",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = sns.catplot(x = \"name\", y = \"mean_ADR\", hue = \"Map\", jitter = False, height = 6, aspect = 3, data = friend_stats_sigificant)\n",
    "plot.set(xlabel =\"Friend\", ylabel = \"Mean ADR per Game\", title ='Mean ADR per Map per Player, Maps with > 10 Games')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f323318-877c-470c-a3c9-8c24428e9655",
   "metadata": {},
   "source": [
    "#### Results\n",
    "\n",
    "There were no major shifts from the Kills plot to the ADR plot, which shows us that everything is just about good. The ADR plot shows less variance than the kills plot does though, as should be expected (only a small difference in ADR can indicate a large difference in kills, as trash damage that doesn't contribute to a kill will boost ADR).\n",
    "\n",
    "## Per Map Exploratory Visualizations\n",
    "\n",
    "### Nuke"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d096a408-200a-4ba4-ade0-e79c12f7aa62",
   "metadata": {},
   "source": [
    "<img src=\"https://vignette.wikia.nocookie.net/cswikia/images/5/51/De_nuke_thumbnail.jpg/revision/latest?cb=20180209112248\" width=\"700\"> <img src=\"https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fwww.tobyscs.com%2Ffiles%2Fcsgo-de_nuke-callout.jpg&f=1&nofb=1\" width=\"394\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bba1f88-cd2f-4942-a8bf-771ea007b5ea",
   "metadata": {},
   "source": [
    "The first map we'll be taking a look at is Nuke, which is one of the most popular maps in CS:GO and is notable for it's complexity relative to the other Active Duty (i.e. played at a competitive level, usually widly enjoyed by the community) maps and it's consistent revisions. Nuke is the one of the only maps in CS:GO with a double-layered design, meaning fast rotation times (time to get from one bombsite to the other) and accurate reading of sound cues is absolutely crucial to success on the map. There is an extreme variety of engagement distances too, with some areas on A site featuring near point-blank engagements and other areas like outside featuring ranges long enough to discourage any player without a sniper, and a vent so claustrophobic that knives are a viable weapon. Nuke is a map that rewards versatile players with good aim more than anything, and it is that very fact that makes this the most popular map for trolling in the game - lookup \"FranzJ\" on youtube."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878be450-ff15-4217-94ba-4004e4f8f571",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuke_stats = friend_tables_joined[friend_tables_joined['Map'] == \"de_nuke\"]\n",
    "plot = sns.catplot(x = \"name\", y = \"K\", hue = \"Map\", kind = \"violin\", height = 6, aspect = 3, data = nuke_stats)\n",
    "plot.set(xlabel =\"Friend\", ylabel = \"Kills per Game\", title ='Mean Kills per Player on Nuke')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07439e57-d4c1-4bca-b060-f887c1e0a0cb",
   "metadata": {},
   "source": [
    "#### Results\n",
    "\n",
    "This is a nice violinplot that is pleasing on the eyes, but we can likely do better with a more readable plot.\n",
    "\n",
    "### Box Plot\n",
    "\n",
    "We can sacrifice a bit of style for readibility by creating a box plot instead - this easily shows the median, percentiles, and outliers and will likely be better for understanding the distribution (all the distributions are roughly normal, so a violin plot doesn't show much that a box plot won't)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ec6522-07f6-48ad-85ab-dfe705477158",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = sns.catplot(x = \"name\", y = \"K\", hue = \"Map\", kind = \"box\", height = 6, aspect = 3, data = nuke_stats)\n",
    "plot.set(xlabel =\"Friend\", ylabel = \"Kills per Game\", title ='Kills per Player on Nuke')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d398a1-ecb8-4444-abc2-84d8d3c5f083",
   "metadata": {},
   "source": [
    "#### Results\n",
    "\n",
    "We can easily see that Zack, Tommy, and I (I being Thomas) performed the best out of everyone with Zack having a few exceptional games. Ethan, Flynn, Kristen, and Jackton are also following close behind with strong performances themselves.\n",
    "\n",
    "### Inferno"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fa7085-22ac-4d44-94b6-158e66f91c7f",
   "metadata": {},
   "source": [
    "<img src=\"http://media.steampowered.com/apps/csgo/images/inferno/asite1-2.jpg?v=1\" width=\"700\"> <img src=\"https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fwww.tobyscs.com%2Ffiles%2Fde_inferno-map-callout.jpg&f=1&nofb=1\" width=\"394\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d8c77e-8d12-4ae1-a235-41e895da1119",
   "metadata": {},
   "source": [
    "The second map we will be looking at is Inferno, a far more traditional map by most standards. Inferno (roughly speaking) sports the familiar three-lane style found in many CS:GO maps with the left/right lanes leading from Terrorist spawn to A site and B site, while the middle lane leads to a longer-range area that allows for rotates to either site. Another mainstay of the CS series is the B site supporting fewer entrances and a more grenade and rush heavy style of play. Similarly to Nuke, Inferno also has a range of engagement distances but all of Inferno's close range engagements are centered in Apartments and at the top of Banana which are natural choke points. This is a map where remembering grenade lineups (spots and angles where you can throw a grenade from for it to land in a certain advantageous spot) can be very instrumental as a Terrorist, and also heavily rewards those with good aim. Rotation times are quite long for Terrorists, so faking the other team out isn't as viable of a strategy on offense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cda9282-d0c6-4575-808c-5d7728ab92a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inferno_stats = friend_tables_joined[friend_tables_joined['Map'] == \"de_inferno\"]\n",
    "plot = sns.catplot(x = \"name\", y = \"K\", hue = \"Map\", kind = \"box\", height = 6, aspect = 3, data = inferno_stats)\n",
    "plot.set(xlabel =\"Friend\", ylabel = \"Kills per Game\", title ='Kills per Player on Inferno')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0feb16bd-ad89-4e82-8b32-261ccd146a41",
   "metadata": {},
   "source": [
    "#### Results\n",
    "\n",
    "Inferno is my strongest map (whereas many of my friends struggle on it), so it's not too surprising that I come out on top, but Eric, Flynn, and Zack (especially that one exceptional game) all did well too. You see a lot more variation among different players here because not all of us have played the map that much, and thus some don't know the map well enough to be very successful.\n",
    "\n",
    "### Mirage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7aebb7d-157b-4b42-bcca-8cfae69de9cf",
   "metadata": {},
   "source": [
    "<img src=\"https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fvignette.wikia.nocookie.net%2Fcswikia%2Fimages%2F1%2F1e%2FCSGO_Mirage_latest_version.jpg%2Frevision%2Flatest%3Fcb%3D20200301201524&f=1&nofb=1\" width=\"700\"> <img src=\"https://steamuserimages-a.akamaihd.net/ugc/902129724392201747/56353A73C55D76033FB0E95C156935FA24B34773/?interpolation=lanczos-none&output-format=jpeg&output-quality=95&fit=inside%7C1024%3A1024&composite-to=*,*%7C1024%3A1024&background-color=black\" width=\"394\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb5d4f2-6dcc-4a02-a451-ea9612477595",
   "metadata": {},
   "source": [
    "Mirage is another extremely popular map sporting CS's typical three-lane style, with B site supporting more rushes and A site encouraging careful use of grenades and a varied attack. Mirage is a map where grenades are absolutely crucial, especially on A site. Mirage has long rotation times but due to the structure of the middle lane, allows for a lot of more complex plays from the Terrorist side. There also aren't very many close range engagements on Mirage so rifles and snipers are favored very heavily. To succeed on Mirage you need a knowledge of grenade lineups and strong strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ec33c1-065e-4e2b-8257-c7afab97d487",
   "metadata": {},
   "outputs": [],
   "source": [
    "inferno_stats = friend_tables_joined[friend_tables_joined['Map'] == \"de_mirage\"]\n",
    "plot = sns.catplot(x = \"name\", y = \"K\", hue = \"Map\", kind = \"box\", height = 6, aspect = 3, data = inferno_stats)\n",
    "plot.set(xlabel =\"Friend\", ylabel = \"Kills per Game\", title ='Kills per Player on Mirage')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3811a8e6-e752-4d9c-b036-c7fc1c62a490",
   "metadata": {},
   "source": [
    "#### Results\n",
    "\n",
    "On Mirage Eric seems to have done the best, but after closer inspection it seems to be because he has only played 8 games on the map. This seems a bit misleading but is overall fine as these visualizations are just meant to give a general idea about our performance, they won't be used in the optimal team creation. Arian seems to only have 1 game on this map, hence the single line, but as for the rest of the data there really isn't a standout \"best player\". Also I am hoping my lower outlier was only a few round game where the other team surrendered, otherwise that is embarassing.\n",
    "\n",
    "### Vertigo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61677a07-7ee1-4d11-a47d-22b112690651",
   "metadata": {},
   "source": [
    "<img src=\"https://vignette.wikia.nocookie.net/cswikia/images/2/2b/CSGO_Vertigo_18_Nov_2019_update.jpg/revision/latest?cb=20200307130224\" width=\"700\"> <img src=\"https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fi.redd.it%2Fqxc0wd7lfip21.png&f=1&nofb=1\" width=\"790\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd96cce-f5c6-49f7-bbc0-d75296dab135",
   "metadata": {},
   "source": [
    "The last map we are looking at is Vertigo, another map outside the norm in CS. Vertigo has somewhat of a double-layered design like Nuke, but unlike Nuke Vertigo has the terrorists spawning on the bottom layer and the Counter-Terrorists on the top layer, along with mostly keeping the bottom layer on one corner of the map and the top layer in the opposite corner. This essentially results in the layered design not mattering nearly as much as nuke, aside from the fact that the Counter-Terrorists almost always having the advantage of the high ground. The one other thing that does matter about Vertigo's double-layered design is the importance of sound cues - each team can hear each other quite easily despite being far apart in terms of walking distance. This combined with the rotation times, choke points in key areas, and abilitly to rotate from one site to the other means that Vertigo is a very strategy-dependent map. Most of the grenades for the terrorist side are mostly reserved for when they are almost already on the site, as they are penned in below and don't have much of an opportunity to throw them, but can still be vital in certain situations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43c5e50-2f37-41d5-ad43-ea0bf19e8522",
   "metadata": {},
   "outputs": [],
   "source": [
    "inferno_stats = friend_tables_joined[friend_tables_joined['Map'] == \"de_vertigo\"]\n",
    "plot = sns.catplot(x = \"name\", y = \"K\", hue = \"Map\", kind = \"box\", height = 6, aspect = 3, data = inferno_stats)\n",
    "plot.set(xlabel =\"Friend\", ylabel = \"Kills per Game\", title ='Kills per Player on Vertigo')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef47b8a-0162-4161-9006-7dca015eac56",
   "metadata": {},
   "source": [
    "#### Results\n",
    "\n",
    "Kristen appears to do quite well but is again an instance where there weren't many games played, so her performance should be considered as unreliable. Arian still has one game, but the rest of us perform decently, some with a noticably very high spread, but no real standouts.\n",
    "\n",
    "## Optimal Team Creation\n",
    "\n",
    "Now we will finally put everything together and generate some optimal teams for each map.\n",
    "\n",
    "### Maximize Function\n",
    "\n",
    "Now we will make a versatile maximize function that will take in the data, desired maps, and estimators, and then will find the \"best\" team for each map based on those estimator functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98519cf3-d8d1-40ab-b88b-971e02473cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function will take in data and estimators and find the best team\n",
    "def maximize(table, maps, methods):\n",
    "    players_per_map = [] #stores the five best players for each map\n",
    "    \n",
    "    #for each map\n",
    "    for csgo_map in maps:\n",
    "        chosen_players = [] #stores the five best players for this map\n",
    "        map_table = table[table['Map'] == csgo_map]\n",
    "        filtered_table = map_table[map_table[\"sum_W\"] + map_table[\"sum_T\"] + map_table[\"sum_L\"]  > 10] #filtered down to the data we want\n",
    "        \n",
    "        #while players still needed\n",
    "        players_found = 0\n",
    "        while players_found < 5:\n",
    "            players = filtered_table.name.unique()\n",
    "            players_score = []\n",
    "            max_score = -1 * 10 ^ (10)\n",
    "            max_player = \"\"\n",
    "\n",
    "            #estimate and find best scoring player\n",
    "            for player in players:\n",
    "                players_score.append(methods[players_found](filtered_table[filtered_table['name'] == player]))\n",
    "                if players_score[-1] > max_score:\n",
    "                    max_score = players_score[-1]\n",
    "                    max_player = player\n",
    "\n",
    "            filtered_table = filtered_table[filtered_table['name'] != max_player] #remove current best player from data\n",
    "            chosen_players.append(max_player) #add to chosen players\n",
    "            players_found += 1 #increment players found\n",
    "            \n",
    "        players_per_map.append(chosen_players)\n",
    "        \n",
    "    #for each map print the map name and players selected\n",
    "    index = 0\n",
    "    while index < len(maps):\n",
    "        print(\"The Best Team for \" + maps[index] + \" is:\")\n",
    "        print(players_per_map[index])\n",
    "        index += 1\n",
    "    return players_per_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a48c95-85af-4c6e-946b-2dd6a2f1269e",
   "metadata": {},
   "source": [
    "### Basic Kill-Based Estimation\n",
    "\n",
    "First off let's try a basic Kill-Based Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b71fe30-7b73-4fa8-afe0-2790bb7bab67",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_maps = ['de_nuke', 'de_inferno', 'de_mirage', 'de_vertigo']\n",
    "def kill_estimator(data):\n",
    "    return data['mean_K'].tolist()[0]\n",
    "\n",
    "print(\"When only accounting for kills:\")\n",
    "value = maximize(friend_stats_joined, target_maps, [kill_estimator] * 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f639f47b-c0ec-43e7-856a-b55bc1774520",
   "metadata": {},
   "source": [
    "#### Results\n",
    "\n",
    "That was a very naive approach as it says that \"kills are the only thing that matters\" and leaves it at that, but it does verify that our maximize function is working. It corroborates our previous visualizations showing who is the best on each map, and is generally a simple but likely effective team composition.\n",
    "\n",
    "### A Slightly More Nuanced Approach\n",
    "\n",
    "Now let's try a estimator that is a little bit smarter - by combining Kills and Assists. I will weight Assists as half a Kill, as that is basically what an Assist is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb8d28d-6a62-46cf-81de-ae8c847f6c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_maps = ['de_nuke', 'de_inferno', 'de_mirage', 'de_vertigo']\n",
    "def kill_assist_estimator(data):\n",
    "    return kill_estimator(data) + (data['mean_A'].tolist()[0] * .5)\n",
    "\n",
    "print(\"When only accounting for kills and assists:\")\n",
    "value = maximize(friend_stats_joined, target_maps, [kill_assist_estimator] * 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7dba33-1296-4776-8130-e0c6c3b7df1b",
   "metadata": {},
   "source": [
    "#### Results\n",
    "\n",
    "This is slightly different, but is just about the same - which shows us that people who get a lot of kills tend to also get a lot of assists, aka no one (amongst the best players) is seriously struggling to finish their kills.\n",
    "\n",
    "### Taking Consistency Into Account\n",
    "\n",
    "Now lets try to find the players who perform the best and are the most consistent by combining standard deviation with the kill_assist_estimator. I am going to account for consistency by multiplying the previous estimator's result by 1/sqrt(standard deviation of Kills) to attempt to punish inconsistent players."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3722b8a-01c2-4f50-9cf6-ba1ec11cca0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_maps = ['de_nuke', 'de_inferno', 'de_mirage', 'de_vertigo']\n",
    "def consistency_estimator(data):\n",
    "    return kill_assist_estimator(data) * (1 / np.sqrt(data['std_K'].tolist()[0]))\n",
    "\n",
    "print(\"When accounting for kills, assists, and consistency:\")\n",
    "value = maximize(friend_stats_joined, target_maps, [consistency_estimator] * 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86561e06-7290-4d51-87e5-5881dc0b2649",
   "metadata": {},
   "source": [
    "#### Results\n",
    "\n",
    "This seems a lot better - I am an extremely inconsistent player (especially on Nuke and Vertigo) so it makes sense that my performance would plumment when accounting for consistency. That being said, I think we can do better.\n",
    "\n",
    "### Including The HLTV Rating\n",
    "\n",
    "As an additional step I will be multiplying the value of the previous estimator by the HLTV rating (~.7 being bad, 1 being average, ~1.3 being good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c630ae4-84c6-4737-be85-72e709d0746f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_maps = ['de_nuke', 'de_inferno', 'de_mirage', 'de_vertigo']\n",
    "def hltv_estimator(data):\n",
    "    return consistency_estimator(data) * ((data['mean_Rating'].tolist()[0]))\n",
    "\n",
    "print(\"When accounting for kills, assists, consistency, and HLTV rating:\")\n",
    "value = maximize(friend_stats_joined, target_maps, [hltv_estimator] * 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf7cc3e-287d-4843-bf45-025d02883c43",
   "metadata": {},
   "source": [
    "#### Results\n",
    "\n",
    "This seems just about right (HLTV rating should be a good all-around estimator), but I have one final variable I want to account for, so I think we can improve this further.\n",
    "\n",
    "### Accounting For Deaths\n",
    "\n",
    "As a final percentage change, I am applying mean Deaths as a negative percentage (i.e. 25 kills equals -25% rating). This sounds like a pretty hefty change, but realistically everyones deaths will be from 12-22 on average, so it's only about a 10% modifier. This will already be partially accounted for in the HLTV rating but I want to apply a negative effect again as Deaths can be very harmful to a team composition - a death means armor and a gun lost for the next round that have to be repurchased, in addition to the impact on the gameplay of the round."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdb88b8-d607-465a-b4a4-e56d9ac66175",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_maps = ['de_nuke', 'de_inferno', 'de_mirage', 'de_vertigo']\n",
    "def overall_estimator(data):\n",
    "    return consistency_estimator(data) * (1 - (data['mean_D'].tolist()[0] / 100))\n",
    "\n",
    "print(\"When accounting for kills, assists, consistency, HLTV rating, and deaths:\")\n",
    "value = maximize(friend_stats_joined, target_maps, [overall_estimator] * 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5ad398-0a86-44cc-b41a-e414666e81df",
   "metadata": {},
   "source": [
    "#### Results\n",
    "\n",
    "This is probably the most accurate estimator yet, and I think I'm satisfied with it. It accounts for a variety of statistics and balances it a sensical way.\n",
    "\n",
    "### Mixing The Estimators\n",
    "\n",
    "Finally I am going to combine two of these estimators as an expiriment: I'll have two people estimated by the Kill + Assist estimator and three people estimated by the overall estimator. The idea is to have two people who get a lot of kills and have three people who are well balanced players."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0603f90-1220-4d1c-af02-b0cac8104b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"When accounting for kills and assists for two people and kills, assists, consistency, HLTV rating, and deaths for the other three:\")\n",
    "value = maximize(friend_stats_joined, target_maps, [kill_assist_estimator, kill_assist_estimator, overall_estimator, overall_estimator, overall_estimator])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76083aa-5172-444d-9721-143550f6275a",
   "metadata": {},
   "source": [
    "#### Results\n",
    "\n",
    "This is really just a bit of an experiment as it is somewhat arbitary, but it makes sense that you want a couple people to get kills and some more consistent players to back them up, so I'd say these results have some validity. I think these compositions actually would work, so I'd say this is a valid estimator.\n",
    "\n",
    "## Conclusion And Final Thoughts\n",
    "\n",
    "If I were to actually use these teams in competitive matchmaking, I am sure they would do well as these are generally just the most skilled people out of my friends. I think the latter teams would be the best (The Overall and Mixed estimator ones), but really it isn't as simple as this analysis makes it out to be. It comes down to who is good at what angles on which maps and who can fullfill what roles on the team; things that cannot be properly represented by raw numbers like this. If all it took to predict the optimum team was a single low-ranked college kid all professional teams would run like clockwork. Again though, I think these team compositions make sense and are generally useful to attempt to create the optimum team amongst your friends. I actually had a lot of fun doing this project and showing all the statistics to my friends and enjoying the chaos it caused among them. All it takes is downloading the HTML of their stats page manually and following the tutorial, and then you can also make your friends angry by saying you're statistically better than them."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
